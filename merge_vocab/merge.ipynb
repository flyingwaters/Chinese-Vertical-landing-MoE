{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import LlamaTokenizer,AutoTokenizer\n",
    "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\n",
    "import sentencepiece as spm\n",
    "import argparse\n",
    "tokenizer_dir = r'../../deepseek-moe-16b-chat'  # 这里是LLaMA tokenizer的路径\n",
    "chinese_sp_model_file = r'../../deepseek.model'  # 这里是Chinese tokenizer的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "deepseek_tokenizer = AutoTokenizer.from_pretrained(tokenizer_dir, trust_remote_code=True)  # 加载LLaMA tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100015"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deepseek_tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_sp_model = spm.SentencePieceProcessor()  # 定义Chinese tokenizer\n",
    "chinese_sp_model.Load(chinese_sp_model_file)  # 加载Chinese tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on SentencePieceProcessor in module sentencepiece object:\n",
      "\n",
      "class SentencePieceProcessor(builtins.object)\n",
      " |  SentencePieceProcessor(model_file=None, model_proto=None, out_type=<class 'int'>, add_bos=False, add_eos=False, reverse=False, emit_unk_piece=False, enable_sampling=False, nbest_size=-1, alpha=0.1, num_threads=-1)\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  CalculateEntropy(self, input, alpha, num_threads=None)\n",
      " |      Calculate sentence entropy\n",
      " |  \n",
      " |  Decode(self, input, out_type=<class 'str'>, num_threads=None)\n",
      " |      Decode processed id or token sequences.\n",
      " |      \n",
      " |      Args:\n",
      " |        out_type: output type. str, bytes or 'serialized_proto' or 'immutable_proto' (Default = str)\n",
      " |        num_threads: the number of threads used in the batch processing (Default = -1).\n",
      " |  \n",
      " |  DecodeIds(self, input, out_type=<class 'str'>, **kwargs)\n",
      " |  \n",
      " |  DecodeIdsAsImmutableProto(self, input, out_type='immutable_proto', **kwargs)\n",
      " |  \n",
      " |  DecodeIdsAsSerializedProto(self, input, out_type='serialized_proto', **kwargs)\n",
      " |  \n",
      " |  DecodePieces(self, input, out_type=<class 'str'>, **kwargs)\n",
      " |  \n",
      " |  DecodePiecesAsImmutableProto(self, input, out_type='immutable_proto', **kwargs)\n",
      " |  \n",
      " |  DecodePiecesAsSerializedProto(self, input, out_type='serialized_proto', **kwargs)\n",
      " |  \n",
      " |  Detokenize = Decode(self, input, out_type=<class 'str'>, num_threads=None)\n",
      " |  \n",
      " |  Encode(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, enable_sampling=None, nbest_size=None, alpha=None, num_threads=None)\n",
      " |      Encode text input to segmented ids or tokens.\n",
      " |      \n",
      " |      Args:\n",
      " |      input: input string. accepsts list of string.\n",
      " |      out_type: output type. int or str.\n",
      " |      add_bos: Add <s> to the result (Default = false)\n",
      " |      add_eos: Add </s> to the result (Default = false) <s>/</s> is added after\n",
      " |               reversing (if enabled).\n",
      " |      reverse: Reverses the tokenized sequence (Default = false)\n",
      " |      emit_unk_piece: Emits the unk literal string (Default = false)\n",
      " |      nbest_size: sampling parameters for unigram. Invalid in BPE-Dropout.\n",
      " |                  nbest_size = {0,1}: No sampling is performed.\n",
      " |                  nbest_size > 1: samples from the nbest_size results.\n",
      " |                  nbest_size < 0: assuming that nbest_size is infinite and samples\n",
      " |                  from the all hypothesis (lattice) using\n",
      " |                  forward-filtering-and-backward-sampling algorithm.\n",
      " |      alpha: Soothing parameter for unigram sampling, and merge probability for\n",
      " |             BPE-dropout (probablity 'p' in BPE-dropout paper).\n",
      " |      num_threads: the number of threads used in the batch processing (Default = -1).\n",
      " |  \n",
      " |  EncodeAsIds(self, input, **kwargs)\n",
      " |  \n",
      " |  EncodeAsImmutableProto(self, input, **kwargs)\n",
      " |  \n",
      " |  EncodeAsPieces(self, input, **kwargs)\n",
      " |  \n",
      " |  EncodeAsSerializedProto(self, input, **kwargs)\n",
      " |  \n",
      " |  GetPieceSize(self)\n",
      " |  \n",
      " |  GetScore = _batched_func(self, arg)\n",
      " |  \n",
      " |  IdToPiece = _batched_func(self, arg)\n",
      " |  \n",
      " |  Init(self, model_file=None, model_proto=None, out_type=<class 'int'>, add_bos=False, add_eos=False, reverse=False, emit_unk_piece=False, enable_sampling=False, nbest_size=-1, alpha=0.1, num_threads=-1)\n",
      " |      Initialzie sentencepieceProcessor.\n",
      " |      \n",
      " |      Args:\n",
      " |        model_file: The sentencepiece model file path.\n",
      " |        model_proto: The sentencepiece model serialized proto.\n",
      " |        out_type: output type. int or str.\n",
      " |        add_bos: Add <s> to the result (Default = false)\n",
      " |        add_eos: Add </s> to the result (Default = false) <s>/</s> is added after\n",
      " |          reversing (if enabled).\n",
      " |        reverse: Reverses the tokenized sequence (Default = false)\n",
      " |        emit_unk_piece: Emits the unk literal string (Default = false)\n",
      " |        nbest_size: sampling parameters for unigram. Invalid in BPE-Dropout.\n",
      " |                    nbest_size = {0,1}: No sampling is performed.\n",
      " |                    nbest_size > 1: samples from the nbest_size results.\n",
      " |                    nbest_size < 0: assuming that nbest_size is infinite and samples\n",
      " |                      from the all hypothesis (lattice) using\n",
      " |                      forward-filtering-and-backward-sampling algorithm.\n",
      " |        alpha: Soothing parameter for unigram sampling, and dropout probability of\n",
      " |               merge operations for BPE-dropout.\n",
      " |        num_threads: number of threads in batch processing (Default = -1, auto-detected)\n",
      " |  \n",
      " |  IsByte = _batched_func(self, arg)\n",
      " |  \n",
      " |  IsControl = _batched_func(self, arg)\n",
      " |  \n",
      " |  IsUnknown = _batched_func(self, arg)\n",
      " |  \n",
      " |  IsUnused = _batched_func(self, arg)\n",
      " |  \n",
      " |  Load(self, model_file=None, model_proto=None)\n",
      " |      Overwride SentencePieceProcessor.Load to support both model_file and model_proto.\n",
      " |      \n",
      " |      Args:\n",
      " |        model_file: The sentencepiece model file path.\n",
      " |        model_proto: The sentencepiece model serialized proto. Either `model_file`\n",
      " |          or `model_proto` must be set.\n",
      " |  \n",
      " |  LoadFromFile(self, arg)\n",
      " |  \n",
      " |  LoadFromSerializedProto(self, serialized)\n",
      " |  \n",
      " |  LoadVocabulary(self, filename, threshold)\n",
      " |  \n",
      " |  NBestEncode(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, nbest_size=None)\n",
      " |      NBestEncode text input to segmented ids or tokens.\n",
      " |      \n",
      " |      Args:\n",
      " |      input: input string. accepsts list of string.\n",
      " |      out_type: output type. int or str.\n",
      " |      add_bos: Add <s> to the result (Default = false)\n",
      " |      add_eos: Add </s> to the result (Default = false) <s>/</s> is added after reversing (if enabled).\n",
      " |      reverse: Reverses the tokenized sequence (Default = false)\n",
      " |      emit_unk_piece: Emits the unk literal string (Default = false)\n",
      " |      nbest_size: nbest size\n",
      " |  \n",
      " |  NBestEncodeAsIds(self, input, nbest_size=None, **kwargs)\n",
      " |  \n",
      " |  NBestEncodeAsImmutableProto(self, input, nbest_size=None, **kwargs)\n",
      " |  \n",
      " |  NBestEncodeAsPieces(self, input, nbest_size=None, **kwargs)\n",
      " |  \n",
      " |  NBestEncodeAsSerializedProto(self, input, nbest_size=None, **kwargs)\n",
      " |  \n",
      " |  Normalize(self, input, with_offsets=None)\n",
      " |  \n",
      " |  OverrideNormalizerSpec(self, **kwargs)\n",
      " |  \n",
      " |  PieceToId = _batched_func(self, arg)\n",
      " |  \n",
      " |  ResetVocabulary(self)\n",
      " |  \n",
      " |  SampleEncodeAndScore(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, num_samples=None, alpha=None, wor=None, include_best=None)\n",
      " |      SampleEncodeAndScore text input to segmented ids or tokens.\n",
      " |      \n",
      " |      Args:\n",
      " |      input: input string. accepsts list of string.\n",
      " |      out_type: output type. int or str or 'serialized_proto' or 'immutable_proto'\n",
      " |      add_bos: Add <s> to the result (Default = false)\n",
      " |      add_eos: Add </s> to the result (Default = false) <s>/</s> is added after reversing (if enabled).\n",
      " |      reverse: Reverses the tokenized sequence (Default = false)\n",
      " |      emit_unk_piece: Emits the unk literal string (Default = false)\n",
      " |      num_samples: How many samples to return (Default = 1)\n",
      " |      alpha: inverse temperature for sampling\n",
      " |      wor: whether to sample without replacement (Default = false)\n",
      " |      include_best: whether to include the best tokenization, requires wor=True (Default = false)\n",
      " |  \n",
      " |  SampleEncodeAndScoreAsIds(self, input, num_samples=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  SampleEncodeAndScoreAsImmutableProto(self, input, num_samples=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  SampleEncodeAndScoreAsPieces(self, input, num_samples=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  SampleEncodeAndScoreAsSerializedProto(self, input, num_samples=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  SampleEncodeAsIds(self, input, nbest_size=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  SampleEncodeAsImmutableProto(self, input, nbest_size=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  SampleEncodeAsPieces(self, input, nbest_size=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  SampleEncodeAsSerializedProto(self, input, nbest_size=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  SetDecodeExtraOptions(self, extra_option)\n",
      " |  \n",
      " |  SetEncodeExtraOptions(self, extra_option)\n",
      " |  \n",
      " |  SetVocabulary(self, valid_vocab)\n",
      " |  \n",
      " |  Tokenize = Encode(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, enable_sampling=None, nbest_size=None, alpha=None, num_threads=None)\n",
      " |  \n",
      " |  __getitem__(self, piece)\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __init__ = Init(self, model_file=None, model_proto=None, out_type=<class 'int'>, add_bos=False, add_eos=False, reverse=False, emit_unk_piece=False, enable_sampling=False, nbest_size=-1, alpha=0.1, num_threads=-1)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __repr__ = _swig_repr(self)\n",
      " |  \n",
      " |  __setstate__(self, serialized_model_proto)\n",
      " |  \n",
      " |  bos_id(self)\n",
      " |  \n",
      " |  calculate_entropy = CalculateEntropy(self, input, alpha, num_threads=None)\n",
      " |  \n",
      " |  decode = Decode(self, input, out_type=<class 'str'>, num_threads=None)\n",
      " |  \n",
      " |  decode_ids = DecodeIds(self, input, out_type=<class 'str'>, **kwargs)\n",
      " |  \n",
      " |  decode_ids_as_immutable_proto = DecodeIdsAsImmutableProto(self, input, out_type='immutable_proto', **kwargs)\n",
      " |  \n",
      " |  decode_ids_as_serialized_proto = DecodeIdsAsSerializedProto(self, input, out_type='serialized_proto', **kwargs)\n",
      " |  \n",
      " |  decode_pieces = DecodePieces(self, input, out_type=<class 'str'>, **kwargs)\n",
      " |  \n",
      " |  decode_pieces_as_immutable_proto = DecodePiecesAsImmutableProto(self, input, out_type='immutable_proto', **kwargs)\n",
      " |  \n",
      " |  decode_pieces_as_serialized_proto = DecodePiecesAsSerializedProto(self, input, out_type='serialized_proto', **kwargs)\n",
      " |  \n",
      " |  detokenize = Decode(self, input, out_type=<class 'str'>, num_threads=None)\n",
      " |  \n",
      " |  encode = Encode(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, enable_sampling=None, nbest_size=None, alpha=None, num_threads=None)\n",
      " |  \n",
      " |  encode_as_ids = EncodeAsIds(self, input, **kwargs)\n",
      " |  \n",
      " |  encode_as_immutable_proto = EncodeAsImmutableProto(self, input, **kwargs)\n",
      " |  \n",
      " |  encode_as_pieces = EncodeAsPieces(self, input, **kwargs)\n",
      " |  \n",
      " |  encode_as_serialized_proto = EncodeAsSerializedProto(self, input, **kwargs)\n",
      " |  \n",
      " |  eos_id(self)\n",
      " |  \n",
      " |  get_piece_size = GetPieceSize(self)\n",
      " |  \n",
      " |  get_score = _batched_func(self, arg)\n",
      " |  \n",
      " |  id_to_piece = _batched_func(self, arg)\n",
      " |  \n",
      " |  init = Init(self, model_file=None, model_proto=None, out_type=<class 'int'>, add_bos=False, add_eos=False, reverse=False, emit_unk_piece=False, enable_sampling=False, nbest_size=-1, alpha=0.1, num_threads=-1)\n",
      " |  \n",
      " |  is_byte = _batched_func(self, arg)\n",
      " |  \n",
      " |  is_control = _batched_func(self, arg)\n",
      " |  \n",
      " |  is_unknown = _batched_func(self, arg)\n",
      " |  \n",
      " |  is_unused = _batched_func(self, arg)\n",
      " |  \n",
      " |  load = Load(self, model_file=None, model_proto=None)\n",
      " |  \n",
      " |  load_from_file = LoadFromFile(self, arg)\n",
      " |  \n",
      " |  load_from_serialized_proto = LoadFromSerializedProto(self, serialized)\n",
      " |  \n",
      " |  load_vocabulary = LoadVocabulary(self, filename, threshold)\n",
      " |  \n",
      " |  nbest_encode = NBestEncode(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, nbest_size=None)\n",
      " |  \n",
      " |  nbest_encode_as_ids = NBestEncodeAsIds(self, input, nbest_size=None, **kwargs)\n",
      " |  \n",
      " |  nbest_encode_as_immutable_proto = NBestEncodeAsImmutableProto(self, input, nbest_size=None, **kwargs)\n",
      " |  \n",
      " |  nbest_encode_as_pieces = NBestEncodeAsPieces(self, input, nbest_size=None, **kwargs)\n",
      " |  \n",
      " |  nbest_encode_as_serialized_proto = NBestEncodeAsSerializedProto(self, input, nbest_size=None, **kwargs)\n",
      " |  \n",
      " |  normalize = Normalize(self, input, with_offsets=None)\n",
      " |  \n",
      " |  override_normalizer_spec = OverrideNormalizerSpec(self, **kwargs)\n",
      " |  \n",
      " |  pad_id(self)\n",
      " |  \n",
      " |  piece_size(self)\n",
      " |  \n",
      " |  piece_to_id = _batched_func(self, arg)\n",
      " |  \n",
      " |  reset_vocabulary = ResetVocabulary(self)\n",
      " |  \n",
      " |  sample_encode_and_score = SampleEncodeAndScore(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, num_samples=None, alpha=None, wor=None, include_best=None)\n",
      " |  \n",
      " |  sample_encode_and_score_as_ids = SampleEncodeAndScoreAsIds(self, input, num_samples=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  sample_encode_and_score_as_immutable_proto = SampleEncodeAndScoreAsImmutableProto(self, input, num_samples=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  sample_encode_and_score_as_pieces = SampleEncodeAndScoreAsPieces(self, input, num_samples=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  sample_encode_and_score_as_serialized_proto = SampleEncodeAndScoreAsSerializedProto(self, input, num_samples=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  sample_encode_as_ids = SampleEncodeAsIds(self, input, nbest_size=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  sample_encode_as_immutable_proto = SampleEncodeAsImmutableProto(self, input, nbest_size=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  sample_encode_as_pieces = SampleEncodeAsPieces(self, input, nbest_size=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  sample_encode_as_serialized_proto = SampleEncodeAsSerializedProto(self, input, nbest_size=None, alpha=None, **kwargs)\n",
      " |  \n",
      " |  serialized_model_proto(self)\n",
      " |  \n",
      " |  set_decode_extra_options = SetDecodeExtraOptions(self, extra_option)\n",
      " |  \n",
      " |  set_encode_extra_options = SetEncodeExtraOptions(self, extra_option)\n",
      " |  \n",
      " |  set_vocabulary = SetVocabulary(self, valid_vocab)\n",
      " |  \n",
      " |  tokenize = Encode(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, enable_sampling=None, nbest_size=None, alpha=None, num_threads=None)\n",
      " |  \n",
      " |  unk_id(self)\n",
      " |  \n",
      " |  vocab_size(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __swig_destroy__ = delete_SentencePieceProcessor(...)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  thisown\n",
      " |      The membership flag\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(chinese_sp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LlamaTokenizerFast' object has no attribute 'sp_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m new_deepseek_spm \u001b[38;5;241m=\u001b[39m sp_pb2_model\u001b[38;5;241m.\u001b[39mModelProto()  \u001b[38;5;66;03m# 定义LLaMA tokenizer的sentencepiece model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m new_deepseek_spm\u001b[38;5;241m.\u001b[39mParseFromString(\u001b[43mdeepseek_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msp_model\u001b[49m\u001b[38;5;241m.\u001b[39mserialized_model_proto())  \u001b[38;5;66;03m# 从LLaMA tokenizer中加载sentencepiece model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m chinese_spm \u001b[38;5;241m=\u001b[39m sp_pb2_model\u001b[38;5;241m.\u001b[39mModelProto()  \u001b[38;5;66;03m# 定义Chinese tokenizer的sentencepiece model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m chinese_spm\u001b[38;5;241m.\u001b[39mParseFromString(chinese_sp_model\u001b[38;5;241m.\u001b[39mserialized_model_proto())  \u001b[38;5;66;03m# 从Chinese tokenizer中加载sentencepiece model\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LlamaTokenizerFast' object has no attribute 'sp_model'"
     ]
    }
   ],
   "source": [
    "new_deepseek_spm = sp_pb2_model.ModelProto()  # 定义LLaMA tokenizer的sentencepiece model\n",
    "new_deepseek_spm.ParseFromString(deepseek_tokenizer.sp_model.serialized_model_proto())  # 从LLaMA tokenizer中加载sentencepiece model\n",
    "chinese_spm = sp_pb2_model.ModelProto()  # 定义Chinese tokenizer的sentencepiece model\n",
    "chinese_spm.ParseFromString(chinese_sp_model.serialized_model_proto())  # 从Chinese tokenizer中加载sentencepiece model\n",
    "\n",
    "# 输出tokens的信息\n",
    "print(len(deepseek_tokenizer), len(chinese_sp_model))  # 两个tokenizer的词表大小；输出为32000、20000\n",
    "print(deepseek_tokenizer.all_special_tokens)  # LLaMA tokenizer的special tokens；输出为['']\n",
    "print(deepseek_tokenizer.all_special_ids)  # LLaMA tokenizer的special tokens对应的id；输出为[0]\n",
    "print(deepseek_tokenizer.special_tokens_map)  # LLaMA tokenizer的special tokens；输出为{'bos_token': '', 'eos_token': '', 'unk_token': ''}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('deepseek-moe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6b80dcee1fdfa01b80b2dd44a21962caf8db036253777b45ed91dbd77686682"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
